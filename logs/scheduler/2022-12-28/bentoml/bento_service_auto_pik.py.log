[2022-12-28T04:17:51.750+0000] {processor.py:156} INFO - Started process (PID=49) to work on /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:17:51.751+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/bentoml/bento_service_auto_pik.py for tasks to queue
[2022-12-28T04:17:51.752+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:17:51.752+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:18:17.899+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:18:17.894+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/bentoml/bento_service_auto_pik.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/bentoml/bento_service_auto_pik.py", line 67, in <module>
    model = BERTopic.load("/opt/airflow/dags/data/bertopic_paraphrase-multilingual-MiniLM-L12-v2_40_20")
  File "/home/airflow/.local/lib/python3.8/site-packages/bertopic/_bertopic.py", line 2197, in load
    topic_model = joblib.load(file)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 648, in load
    obj = _unpickle(fobj)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 577, in _unpickle
    obj = unpickler.load()
  File "/usr/local/lib/python3.8/pickle.py", line 1212, in load
    dispatch[key[0]](self)
  File "/usr/local/lib/python3.8/pickle.py", line 1589, in load_reduce
    stack[-1] = func(*args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/storage.py", line 240, in _load_from_bytes
    return torch.load(io.BytesIO(b))
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 795, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 1012, in _legacy_load
    result = unpickler.load()
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 958, in persistent_load
    wrap_storage=restore_location(obj, location),
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 215, in default_restore_location
    result = fn(storage, location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 182, in _cuda_deserialize
    device = validate_cuda_device(location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 166, in validate_cuda_device
    raise RuntimeError('Attempting to deserialize object on a CUDA '
RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.
[2022-12-28T04:18:17.900+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:18:17.924+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/bentoml/bento_service_auto_pik.py took 26.179 seconds
[2022-12-28T04:18:48.420+0000] {processor.py:156} INFO - Started process (PID=139) to work on /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:18:48.422+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/bentoml/bento_service_auto_pik.py for tasks to queue
[2022-12-28T04:18:48.424+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:18:48.423+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:19:02.984+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:19:02.981+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/bentoml/bento_service_auto_pik.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/bentoml/bento_service_auto_pik.py", line 67, in <module>
    model = BERTopic.load("/opt/airflow/dags/data/bertopic_paraphrase-multilingual-MiniLM-L12-v2_40_20")
  File "/home/airflow/.local/lib/python3.8/site-packages/bertopic/_bertopic.py", line 2197, in load
    topic_model = joblib.load(file)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 648, in load
    obj = _unpickle(fobj)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 577, in _unpickle
    obj = unpickler.load()
  File "/usr/local/lib/python3.8/pickle.py", line 1212, in load
    dispatch[key[0]](self)
  File "/usr/local/lib/python3.8/pickle.py", line 1589, in load_reduce
    stack[-1] = func(*args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/storage.py", line 240, in _load_from_bytes
    return torch.load(io.BytesIO(b))
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 795, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 1012, in _legacy_load
    result = unpickler.load()
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 958, in persistent_load
    wrap_storage=restore_location(obj, location),
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 215, in default_restore_location
    result = fn(storage, location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 182, in _cuda_deserialize
    device = validate_cuda_device(location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 166, in validate_cuda_device
    raise RuntimeError('Attempting to deserialize object on a CUDA '
RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.
[2022-12-28T04:19:02.985+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:19:03.048+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/bentoml/bento_service_auto_pik.py took 14.636 seconds
[2022-12-28T04:19:33.232+0000] {processor.py:156} INFO - Started process (PID=250) to work on /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:19:33.233+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/bentoml/bento_service_auto_pik.py for tasks to queue
[2022-12-28T04:19:33.234+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:19:33.234+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:19:47.385+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:19:47.379+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/bentoml/bento_service_auto_pik.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/bentoml/bento_service_auto_pik.py", line 67, in <module>
    model = BERTopic.load("/opt/airflow/dags/data/bertopic_paraphrase-multilingual-MiniLM-L12-v2_40_20")
  File "/home/airflow/.local/lib/python3.8/site-packages/bertopic/_bertopic.py", line 2197, in load
    topic_model = joblib.load(file)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 648, in load
    obj = _unpickle(fobj)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 577, in _unpickle
    obj = unpickler.load()
  File "/usr/local/lib/python3.8/pickle.py", line 1212, in load
    dispatch[key[0]](self)
  File "/usr/local/lib/python3.8/pickle.py", line 1589, in load_reduce
    stack[-1] = func(*args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/storage.py", line 240, in _load_from_bytes
    return torch.load(io.BytesIO(b))
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 795, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 1012, in _legacy_load
    result = unpickler.load()
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 958, in persistent_load
    wrap_storage=restore_location(obj, location),
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 215, in default_restore_location
    result = fn(storage, location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 182, in _cuda_deserialize
    device = validate_cuda_device(location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 166, in validate_cuda_device
    raise RuntimeError('Attempting to deserialize object on a CUDA '
RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.
[2022-12-28T04:19:47.386+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:19:47.424+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/bentoml/bento_service_auto_pik.py took 14.195 seconds
[2022-12-28T04:20:17.690+0000] {processor.py:156} INFO - Started process (PID=340) to work on /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:20:17.691+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/bentoml/bento_service_auto_pik.py for tasks to queue
[2022-12-28T04:20:17.692+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:20:17.692+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:20:30.280+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:20:30.277+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/bentoml/bento_service_auto_pik.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/bentoml/bento_service_auto_pik.py", line 67, in <module>
    model = BERTopic.load("/opt/airflow/dags/data/bertopic_paraphrase-multilingual-MiniLM-L12-v2_40_20")
  File "/home/airflow/.local/lib/python3.8/site-packages/bertopic/_bertopic.py", line 2197, in load
    topic_model = joblib.load(file)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 648, in load
    obj = _unpickle(fobj)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 577, in _unpickle
    obj = unpickler.load()
  File "/usr/local/lib/python3.8/pickle.py", line 1212, in load
    dispatch[key[0]](self)
  File "/usr/local/lib/python3.8/pickle.py", line 1589, in load_reduce
    stack[-1] = func(*args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/storage.py", line 240, in _load_from_bytes
    return torch.load(io.BytesIO(b))
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 795, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 1012, in _legacy_load
    result = unpickler.load()
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 958, in persistent_load
    wrap_storage=restore_location(obj, location),
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 215, in default_restore_location
    result = fn(storage, location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 182, in _cuda_deserialize
    device = validate_cuda_device(location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 166, in validate_cuda_device
    raise RuntimeError('Attempting to deserialize object on a CUDA '
RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.
[2022-12-28T04:20:30.280+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:20:30.302+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/bentoml/bento_service_auto_pik.py took 12.619 seconds
[2022-12-28T04:21:00.512+0000] {processor.py:156} INFO - Started process (PID=428) to work on /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:21:00.522+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/bentoml/bento_service_auto_pik.py for tasks to queue
[2022-12-28T04:21:00.522+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:21:00.522+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:21:12.079+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:21:12.076+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/bentoml/bento_service_auto_pik.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/bentoml/bento_service_auto_pik.py", line 67, in <module>
    model = BERTopic.load("/opt/airflow/dags/data/bertopic_paraphrase-multilingual-MiniLM-L12-v2_40_20")
  File "/home/airflow/.local/lib/python3.8/site-packages/bertopic/_bertopic.py", line 2197, in load
    topic_model = joblib.load(file)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 648, in load
    obj = _unpickle(fobj)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 577, in _unpickle
    obj = unpickler.load()
  File "/usr/local/lib/python3.8/pickle.py", line 1212, in load
    dispatch[key[0]](self)
  File "/usr/local/lib/python3.8/pickle.py", line 1589, in load_reduce
    stack[-1] = func(*args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/storage.py", line 240, in _load_from_bytes
    return torch.load(io.BytesIO(b))
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 795, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 1012, in _legacy_load
    result = unpickler.load()
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 958, in persistent_load
    wrap_storage=restore_location(obj, location),
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 215, in default_restore_location
    result = fn(storage, location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 182, in _cuda_deserialize
    device = validate_cuda_device(location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 166, in validate_cuda_device
    raise RuntimeError('Attempting to deserialize object on a CUDA '
RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.
[2022-12-28T04:21:12.080+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:21:12.113+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/bentoml/bento_service_auto_pik.py took 11.605 seconds
[2022-12-28T04:21:42.226+0000] {processor.py:156} INFO - Started process (PID=539) to work on /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:21:42.236+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/bentoml/bento_service_auto_pik.py for tasks to queue
[2022-12-28T04:21:42.237+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:21:42.237+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:21:54.691+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:21:54.688+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/bentoml/bento_service_auto_pik.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/bentoml/bento_service_auto_pik.py", line 67, in <module>
    model = BERTopic.load("/opt/airflow/dags/data/bertopic_paraphrase-multilingual-MiniLM-L12-v2_40_20")
  File "/home/airflow/.local/lib/python3.8/site-packages/bertopic/_bertopic.py", line 2197, in load
    topic_model = joblib.load(file)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 648, in load
    obj = _unpickle(fobj)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 577, in _unpickle
    obj = unpickler.load()
  File "/usr/local/lib/python3.8/pickle.py", line 1212, in load
    dispatch[key[0]](self)
  File "/usr/local/lib/python3.8/pickle.py", line 1589, in load_reduce
    stack[-1] = func(*args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/storage.py", line 240, in _load_from_bytes
    return torch.load(io.BytesIO(b))
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 795, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 1012, in _legacy_load
    result = unpickler.load()
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 958, in persistent_load
    wrap_storage=restore_location(obj, location),
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 215, in default_restore_location
    result = fn(storage, location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 182, in _cuda_deserialize
    device = validate_cuda_device(location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 166, in validate_cuda_device
    raise RuntimeError('Attempting to deserialize object on a CUDA '
RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.
[2022-12-28T04:21:54.691+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:21:54.723+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/bentoml/bento_service_auto_pik.py took 12.500 seconds
[2022-12-28T04:22:25.101+0000] {processor.py:156} INFO - Started process (PID=629) to work on /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:22:25.111+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/bentoml/bento_service_auto_pik.py for tasks to queue
[2022-12-28T04:22:25.112+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:22:25.112+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:22:38.066+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:22:38.063+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/bentoml/bento_service_auto_pik.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/bentoml/bento_service_auto_pik.py", line 67, in <module>
    model = BERTopic.load("/opt/airflow/dags/data/bertopic_paraphrase-multilingual-MiniLM-L12-v2_40_20")
  File "/home/airflow/.local/lib/python3.8/site-packages/bertopic/_bertopic.py", line 2197, in load
    topic_model = joblib.load(file)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 648, in load
    obj = _unpickle(fobj)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 577, in _unpickle
    obj = unpickler.load()
  File "/usr/local/lib/python3.8/pickle.py", line 1212, in load
    dispatch[key[0]](self)
  File "/usr/local/lib/python3.8/pickle.py", line 1589, in load_reduce
    stack[-1] = func(*args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/storage.py", line 240, in _load_from_bytes
    return torch.load(io.BytesIO(b))
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 795, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 1012, in _legacy_load
    result = unpickler.load()
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 958, in persistent_load
    wrap_storage=restore_location(obj, location),
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 215, in default_restore_location
    result = fn(storage, location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 182, in _cuda_deserialize
    device = validate_cuda_device(location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 166, in validate_cuda_device
    raise RuntimeError('Attempting to deserialize object on a CUDA '
RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.
[2022-12-28T04:22:38.066+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:22:38.098+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/bentoml/bento_service_auto_pik.py took 13.002 seconds
[2022-12-28T04:23:08.396+0000] {processor.py:156} INFO - Started process (PID=717) to work on /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:23:08.397+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/bentoml/bento_service_auto_pik.py for tasks to queue
[2022-12-28T04:23:08.398+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:23:08.398+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:23:34.080+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:23:34.064+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/bentoml/bento_service_auto_pik.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/bentoml/bento_service_auto_pik.py", line 67, in <module>
    model = BERTopic.load("/opt/airflow/dags/data/bertopic_paraphrase-multilingual-MiniLM-L12-v2_40_20")
  File "/home/airflow/.local/lib/python3.8/site-packages/bertopic/_bertopic.py", line 2197, in load
    topic_model = joblib.load(file)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 648, in load
    obj = _unpickle(fobj)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 577, in _unpickle
    obj = unpickler.load()
  File "/usr/local/lib/python3.8/pickle.py", line 1212, in load
    dispatch[key[0]](self)
  File "/usr/local/lib/python3.8/pickle.py", line 1589, in load_reduce
    stack[-1] = func(*args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/storage.py", line 240, in _load_from_bytes
    return torch.load(io.BytesIO(b))
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 795, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 1012, in _legacy_load
    result = unpickler.load()
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 958, in persistent_load
    wrap_storage=restore_location(obj, location),
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 215, in default_restore_location
    result = fn(storage, location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 182, in _cuda_deserialize
    device = validate_cuda_device(location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 166, in validate_cuda_device
    raise RuntimeError('Attempting to deserialize object on a CUDA '
RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.
[2022-12-28T04:23:34.082+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:23:34.152+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/bentoml/bento_service_auto_pik.py took 25.760 seconds
[2022-12-28T04:24:05.169+0000] {processor.py:156} INFO - Started process (PID=828) to work on /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:24:05.180+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/bentoml/bento_service_auto_pik.py for tasks to queue
[2022-12-28T04:24:05.181+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:24:05.181+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:24:22.881+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:24:22.877+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/bentoml/bento_service_auto_pik.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/bentoml/bento_service_auto_pik.py", line 67, in <module>
    model = BERTopic.load("/opt/airflow/dags/data/bertopic_paraphrase-multilingual-MiniLM-L12-v2_40_20")
  File "/home/airflow/.local/lib/python3.8/site-packages/bertopic/_bertopic.py", line 2197, in load
    topic_model = joblib.load(file)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 648, in load
    obj = _unpickle(fobj)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 577, in _unpickle
    obj = unpickler.load()
  File "/usr/local/lib/python3.8/pickle.py", line 1212, in load
    dispatch[key[0]](self)
  File "/usr/local/lib/python3.8/pickle.py", line 1589, in load_reduce
    stack[-1] = func(*args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/storage.py", line 240, in _load_from_bytes
    return torch.load(io.BytesIO(b))
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 795, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 1012, in _legacy_load
    result = unpickler.load()
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 958, in persistent_load
    wrap_storage=restore_location(obj, location),
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 215, in default_restore_location
    result = fn(storage, location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 182, in _cuda_deserialize
    device = validate_cuda_device(location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 166, in validate_cuda_device
    raise RuntimeError('Attempting to deserialize object on a CUDA '
RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.
[2022-12-28T04:24:22.882+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:24:22.927+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/bentoml/bento_service_auto_pik.py took 17.765 seconds
[2022-12-28T04:24:53.658+0000] {processor.py:156} INFO - Started process (PID=918) to work on /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:24:53.669+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/bentoml/bento_service_auto_pik.py for tasks to queue
[2022-12-28T04:24:53.670+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:24:53.670+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:25:13.716+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:25:13.708+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/bentoml/bento_service_auto_pik.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/bentoml/bento_service_auto_pik.py", line 67, in <module>
    model = BERTopic.load("/opt/airflow/dags/data/bertopic_paraphrase-multilingual-MiniLM-L12-v2_40_20")
  File "/home/airflow/.local/lib/python3.8/site-packages/bertopic/_bertopic.py", line 2197, in load
    topic_model = joblib.load(file)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 648, in load
    obj = _unpickle(fobj)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 577, in _unpickle
    obj = unpickler.load()
  File "/usr/local/lib/python3.8/pickle.py", line 1212, in load
    dispatch[key[0]](self)
  File "/usr/local/lib/python3.8/pickle.py", line 1589, in load_reduce
    stack[-1] = func(*args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/storage.py", line 240, in _load_from_bytes
    return torch.load(io.BytesIO(b))
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 795, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 1012, in _legacy_load
    result = unpickler.load()
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 958, in persistent_load
    wrap_storage=restore_location(obj, location),
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 215, in default_restore_location
    result = fn(storage, location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 182, in _cuda_deserialize
    device = validate_cuda_device(location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 166, in validate_cuda_device
    raise RuntimeError('Attempting to deserialize object on a CUDA '
RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.
[2022-12-28T04:25:13.717+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:25:13.767+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/bentoml/bento_service_auto_pik.py took 20.116 seconds
[2022-12-28T04:25:44.247+0000] {processor.py:156} INFO - Started process (PID=1029) to work on /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:25:44.268+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/bentoml/bento_service_auto_pik.py for tasks to queue
[2022-12-28T04:25:44.270+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:25:44.270+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:25:57.815+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:25:57.809+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/bentoml/bento_service_auto_pik.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/bentoml/bento_service_auto_pik.py", line 67, in <module>
    model = BERTopic.load("/opt/airflow/dags/data/bertopic_paraphrase-multilingual-MiniLM-L12-v2_40_20")
  File "/home/airflow/.local/lib/python3.8/site-packages/bertopic/_bertopic.py", line 2197, in load
    topic_model = joblib.load(file)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 648, in load
    obj = _unpickle(fobj)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 577, in _unpickle
    obj = unpickler.load()
  File "/usr/local/lib/python3.8/pickle.py", line 1212, in load
    dispatch[key[0]](self)
  File "/usr/local/lib/python3.8/pickle.py", line 1589, in load_reduce
    stack[-1] = func(*args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/storage.py", line 240, in _load_from_bytes
    return torch.load(io.BytesIO(b))
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 795, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 1012, in _legacy_load
    result = unpickler.load()
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 958, in persistent_load
    wrap_storage=restore_location(obj, location),
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 215, in default_restore_location
    result = fn(storage, location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 182, in _cuda_deserialize
    device = validate_cuda_device(location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 166, in validate_cuda_device
    raise RuntimeError('Attempting to deserialize object on a CUDA '
RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.
[2022-12-28T04:25:57.816+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:25:57.843+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/bentoml/bento_service_auto_pik.py took 13.606 seconds
[2022-12-28T04:26:28.318+0000] {processor.py:156} INFO - Started process (PID=1119) to work on /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:26:28.329+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/bentoml/bento_service_auto_pik.py for tasks to queue
[2022-12-28T04:26:28.331+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:26:28.331+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:26:42.551+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:26:42.548+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/bentoml/bento_service_auto_pik.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/bentoml/bento_service_auto_pik.py", line 67, in <module>
    model = BERTopic.load("/opt/airflow/dags/data/bertopic_paraphrase-multilingual-MiniLM-L12-v2_40_20")
  File "/home/airflow/.local/lib/python3.8/site-packages/bertopic/_bertopic.py", line 2197, in load
    topic_model = joblib.load(file)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 648, in load
    obj = _unpickle(fobj)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 577, in _unpickle
    obj = unpickler.load()
  File "/usr/local/lib/python3.8/pickle.py", line 1212, in load
    dispatch[key[0]](self)
  File "/usr/local/lib/python3.8/pickle.py", line 1589, in load_reduce
    stack[-1] = func(*args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/storage.py", line 240, in _load_from_bytes
    return torch.load(io.BytesIO(b))
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 795, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 1012, in _legacy_load
    result = unpickler.load()
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 958, in persistent_load
    wrap_storage=restore_location(obj, location),
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 215, in default_restore_location
    result = fn(storage, location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 182, in _cuda_deserialize
    device = validate_cuda_device(location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 166, in validate_cuda_device
    raise RuntimeError('Attempting to deserialize object on a CUDA '
RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.
[2022-12-28T04:26:42.552+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:26:42.583+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/bentoml/bento_service_auto_pik.py took 14.270 seconds
[2022-12-28T04:27:13.100+0000] {processor.py:156} INFO - Started process (PID=1230) to work on /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:27:13.100+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/bentoml/bento_service_auto_pik.py for tasks to queue
[2022-12-28T04:27:13.101+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:27:13.101+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:27:25.454+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:27:25.452+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/bentoml/bento_service_auto_pik.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/bentoml/bento_service_auto_pik.py", line 67, in <module>
    model = BERTopic.load("/opt/airflow/dags/data/bertopic_paraphrase-multilingual-MiniLM-L12-v2_40_20")
  File "/home/airflow/.local/lib/python3.8/site-packages/bertopic/_bertopic.py", line 2197, in load
    topic_model = joblib.load(file)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 648, in load
    obj = _unpickle(fobj)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 577, in _unpickle
    obj = unpickler.load()
  File "/usr/local/lib/python3.8/pickle.py", line 1212, in load
    dispatch[key[0]](self)
  File "/usr/local/lib/python3.8/pickle.py", line 1589, in load_reduce
    stack[-1] = func(*args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/storage.py", line 240, in _load_from_bytes
    return torch.load(io.BytesIO(b))
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 795, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 1012, in _legacy_load
    result = unpickler.load()
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 958, in persistent_load
    wrap_storage=restore_location(obj, location),
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 215, in default_restore_location
    result = fn(storage, location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 182, in _cuda_deserialize
    device = validate_cuda_device(location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 166, in validate_cuda_device
    raise RuntimeError('Attempting to deserialize object on a CUDA '
RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.
[2022-12-28T04:27:25.455+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:27:25.489+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/bentoml/bento_service_auto_pik.py took 12.393 seconds
[2022-12-28T04:27:55.615+0000] {processor.py:156} INFO - Started process (PID=1318) to work on /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:27:55.624+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/bentoml/bento_service_auto_pik.py for tasks to queue
[2022-12-28T04:27:55.625+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:27:55.625+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:28:08.349+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:28:08.347+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/bentoml/bento_service_auto_pik.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/bentoml/bento_service_auto_pik.py", line 67, in <module>
    model = BERTopic.load("/opt/airflow/dags/data/bertopic_paraphrase-multilingual-MiniLM-L12-v2_40_20")
  File "/home/airflow/.local/lib/python3.8/site-packages/bertopic/_bertopic.py", line 2197, in load
    topic_model = joblib.load(file)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 648, in load
    obj = _unpickle(fobj)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 577, in _unpickle
    obj = unpickler.load()
  File "/usr/local/lib/python3.8/pickle.py", line 1212, in load
    dispatch[key[0]](self)
  File "/usr/local/lib/python3.8/pickle.py", line 1589, in load_reduce
    stack[-1] = func(*args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/storage.py", line 240, in _load_from_bytes
    return torch.load(io.BytesIO(b))
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 795, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 1012, in _legacy_load
    result = unpickler.load()
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 958, in persistent_load
    wrap_storage=restore_location(obj, location),
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 215, in default_restore_location
    result = fn(storage, location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 182, in _cuda_deserialize
    device = validate_cuda_device(location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 166, in validate_cuda_device
    raise RuntimeError('Attempting to deserialize object on a CUDA '
RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.
[2022-12-28T04:28:08.350+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:28:08.397+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/bentoml/bento_service_auto_pik.py took 12.786 seconds
[2022-12-28T04:28:38.830+0000] {processor.py:156} INFO - Started process (PID=1408) to work on /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:28:38.840+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/bentoml/bento_service_auto_pik.py for tasks to queue
[2022-12-28T04:28:38.841+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:28:38.840+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:28:49.555+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:28:49.553+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/bentoml/bento_service_auto_pik.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/bentoml/bento_service_auto_pik.py", line 67, in <module>
    model = BERTopic.load("/opt/airflow/dags/data/bertopic_paraphrase-multilingual-MiniLM-L12-v2_40_20")
  File "/home/airflow/.local/lib/python3.8/site-packages/bertopic/_bertopic.py", line 2197, in load
    topic_model = joblib.load(file)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 648, in load
    obj = _unpickle(fobj)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 577, in _unpickle
    obj = unpickler.load()
  File "/usr/local/lib/python3.8/pickle.py", line 1212, in load
    dispatch[key[0]](self)
  File "/usr/local/lib/python3.8/pickle.py", line 1589, in load_reduce
    stack[-1] = func(*args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/storage.py", line 240, in _load_from_bytes
    return torch.load(io.BytesIO(b))
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 795, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 1012, in _legacy_load
    result = unpickler.load()
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 958, in persistent_load
    wrap_storage=restore_location(obj, location),
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 215, in default_restore_location
    result = fn(storage, location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 182, in _cuda_deserialize
    device = validate_cuda_device(location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 166, in validate_cuda_device
    raise RuntimeError('Attempting to deserialize object on a CUDA '
RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.
[2022-12-28T04:28:49.556+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:28:49.588+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/bentoml/bento_service_auto_pik.py took 10.762 seconds
[2022-12-28T04:29:20.007+0000] {processor.py:156} INFO - Started process (PID=1519) to work on /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:29:20.017+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/bentoml/bento_service_auto_pik.py for tasks to queue
[2022-12-28T04:29:20.018+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:29:20.018+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:29:32.290+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:29:32.283+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/bentoml/bento_service_auto_pik.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/bentoml/bento_service_auto_pik.py", line 67, in <module>
    model = BERTopic.load("/opt/airflow/dags/data/bertopic_paraphrase-multilingual-MiniLM-L12-v2_40_20")
  File "/home/airflow/.local/lib/python3.8/site-packages/bertopic/_bertopic.py", line 2197, in load
    topic_model = joblib.load(file)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 648, in load
    obj = _unpickle(fobj)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 577, in _unpickle
    obj = unpickler.load()
  File "/usr/local/lib/python3.8/pickle.py", line 1212, in load
    dispatch[key[0]](self)
  File "/usr/local/lib/python3.8/pickle.py", line 1589, in load_reduce
    stack[-1] = func(*args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/storage.py", line 240, in _load_from_bytes
    return torch.load(io.BytesIO(b))
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 795, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 1012, in _legacy_load
    result = unpickler.load()
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 958, in persistent_load
    wrap_storage=restore_location(obj, location),
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 215, in default_restore_location
    result = fn(storage, location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 182, in _cuda_deserialize
    device = validate_cuda_device(location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 166, in validate_cuda_device
    raise RuntimeError('Attempting to deserialize object on a CUDA '
RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.
[2022-12-28T04:29:32.291+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:29:32.363+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/bentoml/bento_service_auto_pik.py took 12.360 seconds
[2022-12-28T04:30:02.577+0000] {processor.py:156} INFO - Started process (PID=1607) to work on /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:30:02.588+0000] {processor.py:758} INFO - Processing file /opt/airflow/dags/bentoml/bento_service_auto_pik.py for tasks to queue
[2022-12-28T04:30:02.590+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:30:02.589+0000] {dagbag.py:525} INFO - Filling up the DagBag from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:30:14.169+0000] {logging_mixin.py:117} INFO - [2022-12-28T04:30:14.166+0000] {dagbag.py:330} ERROR - Failed to import: /opt/airflow/dags/bentoml/bento_service_auto_pik.py
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.8/site-packages/airflow/models/dagbag.py", line 326, in parse
    loader.exec_module(new_module)
  File "<frozen importlib._bootstrap_external>", line 843, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "/opt/airflow/dags/bentoml/bento_service_auto_pik.py", line 67, in <module>
    model = BERTopic.load("/opt/airflow/dags/data/bertopic_paraphrase-multilingual-MiniLM-L12-v2_40_20")
  File "/home/airflow/.local/lib/python3.8/site-packages/bertopic/_bertopic.py", line 2197, in load
    topic_model = joblib.load(file)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 648, in load
    obj = _unpickle(fobj)
  File "/home/airflow/.local/lib/python3.8/site-packages/joblib/numpy_pickle.py", line 577, in _unpickle
    obj = unpickler.load()
  File "/usr/local/lib/python3.8/pickle.py", line 1212, in load
    dispatch[key[0]](self)
  File "/usr/local/lib/python3.8/pickle.py", line 1589, in load_reduce
    stack[-1] = func(*args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/storage.py", line 240, in _load_from_bytes
    return torch.load(io.BytesIO(b))
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 795, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 1012, in _legacy_load
    result = unpickler.load()
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 958, in persistent_load
    wrap_storage=restore_location(obj, location),
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 215, in default_restore_location
    result = fn(storage, location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 182, in _cuda_deserialize
    device = validate_cuda_device(location)
  File "/home/airflow/.local/lib/python3.8/site-packages/torch/serialization.py", line 166, in validate_cuda_device
    raise RuntimeError('Attempting to deserialize object on a CUDA '
RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.
[2022-12-28T04:30:14.169+0000] {processor.py:770} WARNING - No viable dags retrieved from /opt/airflow/dags/bentoml/bento_service_auto_pik.py
[2022-12-28T04:30:14.221+0000] {processor.py:178} INFO - Processing /opt/airflow/dags/bentoml/bento_service_auto_pik.py took 11.651 seconds
